view = {
  name = myView
  output.schema.url = "host:port/myView"
  output.schema.class = org.hypertrace.core.viewcreator.test.api.TestView
}

pinot = {
  controllerHost = localhost
  controllerPort = 9000
  timeColumn = start_time_millis
  timeUnit = MILLISECONDS
  dimensionColumns = [duration_millis, end_time_millis, services, transaction_name, trace_id]
  columnsMaxLength={transaction_name: 12}
  metricColumns = [num_spans, num_services]
  invertedIndexColumns = [tags__KEYS, tags__VALUES]
  bloomFilterColumns = []
  noDictionaryColumns = []
  rangeIndexColumns = []
  tableName = myView1
  loadMode = MMAP
  numReplicas = 1
  retentionTimeValue = 3
  retentionTimeUnit = DAYS
  brokerTenant = defaultBroker
  serverTenant = defaultServer
  segmentAssignmentStrategy = BalanceNumSegmentAssignmentStrategy
}

pinotRealtime = {
  streamConfigs = {
    streamType: kafka,
    stream.kafka.consumer.type: simple,
    stream.kafka.topic.name: raw-trace-view-events,
    stream.kafka.decoder.class.name: org.apache.pinot.core.realtime.stream.SimpleAvroMessageDecoder,
    stream.kafka.hlc.zk.connect.string: "localhost:2191",
    stream.kafka.zk.broker.url: "localhost:2191",
    stream.kafka.broker.list: "localhost:9092",
    realtime.segment.flush.threshold.time: 3600000,
    realtime.segment.flush.threshold.size: 50000,
    stream.kafka.consumer.prop.auto.offset.reset: smallest
  }
}
